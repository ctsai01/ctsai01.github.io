{"pages":[],"posts":[{"title":"2019 淘寶雙十一購物","text":"2019 淘寶雙十一購物 以下為雙十一的解釋 擷取自wikipedia 雙十一（英文：double 11），是指每年11月11日的大型促銷活動，最早起源於中國電商巨頭阿里巴巴旗下購物網站在2009年11月11日舉辦的「淘寶商城促銷日」，現已演變成全行業一年一度的覆蓋線上線下的購物活動，及影響全球零售業的消費現象。「雙十一」的發起者阿里巴巴CEO張勇將雙十一稱為「商業界的奧林匹克」[1]。2012年11月11日網路購物全日銷售額超過美國網路星期一，成為全球最大的網際網路的購物節日。[2] 是許多商家都會在雙十一展開特價，今年當然也不意外許多商家也展開特價，而我抱著看看的心態到淘寶看看，結果一個禮拜後這些東西就莫名奇妙出現在我家了… 包裹們 鍵盤手拖: 276 元 整線束帶: 81 元 / 五公尺 保護套： 80 元 / 兩個 桌面整線器: 85 元 / 兩個 三合一磁吸充電線: 76 元 / 一條 磁吸充電線動畫 TOPK月牙快充磁吸充電線強磁: 127 元 / 一條 保護貼：76 元 / 兩張 品項 價格 桌面理線器 85 漁網磁吸充電線 67 月牙磁吸充電線 127 五公尺整線束帶 81 閃魔保護貼 *2 152 實木手托 276 手機保護殼 *2 80 總價 868","link":"/2019/11/11/2019_taobao_shopping/"},{"title":"部落格的誕生","text":"退伍後的生活 回想起兩年前的今天，我還是個剛上研究所兩個月的碩一新生，而兩年後的今天我已從碩班畢業，並且完成兵役，說來實在非常幸運,我在論文口試日期都還有確定日期的情況下，便申請了提前入伍，而也如願在 7/18 入伍，並在 10/30 順利的結束兵役，真的非常感謝教授，而在當兵的這段期間其實我也一直在思考未來的方向。 退伍後距離答應公司到職日其實還有一個月左右的時間，於是就利用這個月的時間到新竹找女友，大約一週三天，每天的行程就是起床載她去上班然後在自己到圖書館唸書，雖然已經在工作的朋友都建議應該要出去玩的,因為上班後可以利用的自由時間會變得非常短，但想想之後短時間內應該沒有機會能跟女友一起住，所以就利用這一個月的時間體驗一下外宿生活，畢竟除了去年暑假到台中的實習在台中住了兩個月外從小到大我都是住家裡XD 正式上班前的圖書館日常 建立網站原因 當然讀書、刷題其實說不上枯燥乏味，雖然題目跟書中的內容都不同，但每天都一樣的生活其實還是蠻容易膩的，於是想起過去曾學過 django, css, html 等等，所以就決定利用空閒時間做個Blog 可以記錄一下生活點滴，過去大學時期記得班上有個女生作文很厲害並且常常看到她分享一些自己的文章，當初只覺得字好多，但現在回頭想想如果能用文字記錄生活何嘗不是一件壞事呢，畢竟有些事情不記錄下來可能時間久了就忘了~ 網站部署環境 雖然現在有很多服務像是 WEEBLY, WORDPRESS 等等，都可以幫助使用者快速地建立一個網站，但是在眾多因素的考量下我還是決定自己從頭弄一個，也算是另類的side project !? 最後也很慶幸自己能生在這樣的年代，因為網路的普及如果想要學習任何新知識都變得非常容易，網站的部署，後端伺服器，網域名稱註冊，等等都已經變得非常容易。網站後端不需要像過去自己用一台電腦，甚至連到 AWS, GCP 上面租用一台Server去做部署 都可以省掉，因為這樣還要去部署Server 作業的環境，而最終選用 Serverless 的架構，減少了維護成本與時間，利用 Google App Engine 來部署網站，因為過去學習的經驗曾經租過 Google 的 VM Instance 說實在話環境的設定真的蠻繁瑣的，而也在部署的當天購買了網域名稱 mikeTW.com，也因為這些方便的服務從開始做到實際上線只花了5天的時間，至於網站還有很多功能不完整會在未來慢慢的補齊，但至少已經可以開始寫一點生活的大小事了～","link":"/2019/10/31/blog_init/"},{"title":"解除 Mega 單日流量限制","text":"解除 Mega 流量限制 (2021/04) 問題描述 Mega 每日有 5GB 流量限制，若要下載更大的檔案則需要付費升級。 針對大檔案下載解法 若要下載超過 5 GB 檔案可以使用以下方式完成下載 等待 6 小時冷卻時間 (免費, 耗時間) 升級付費會員 (付費) 透過 proxy 繞過 下載限制 (免費) 本篇文章會針對第三種方式進行大檔案下載， 並使用國外大大所開源的專案 megabasterd 進行 Proxy 設定, 透過幾步驟簡單設定即可繞過檔案限制。 Megabasterd 使用方式 安裝環境 (若電腦有安裝過可以跳過該步驟) 由於作者是使用 java 刻的，所以必須安裝此環境程式可以順利跑起來～ 下載網址: https://java.com/zh-TW/ 下載主程式 下載網址: https://github.com/tonikelope/megabasterd/releases/tag/v7.40 這邊可以看到多種版本, 請下載 .jar 檔結尾的 (25.1MB 那個) 設定 API Key 運行主程式 12345# 切換到主程式所在路徑 這邊假設放在桌面下$ cd ~/Desktop# 運行主程式$ java -jar test.jar 這時應該會跳出請您設定 api key 的界面 這邊可以隨便打只要把隨機產生的 App key 記下來即可 這時回到主程式設定對應的 App key, Edit -&gt; Settings -&gt; Advanced key -&gt; Mega api key -&gt; 填入剛剛產出的 key 設定 proxy https://us-proxy.org/ http://free-proxy.cz/en/proxylist/country/TW/all/ping/all 透過上方網址可以拿到許多可以用的 proxy。 EDIT -&gt; Settings 往下拉可以看到 smart proxy, 勾選 Use SmartProxy, 並將上面得到的proxy 網址按照 IP:Port 格式填入即可。 Let’s Dance, Baby 終於完成所有設置，之後下載檔案只須執行 Let’s Dance, Baby 這步驟即可XD 點擊 File -&gt; New Download -&gt; 填入需要下載的 mega 檔案網址 -&gt; 按下 Let’s dance, baby XD 可以看到即使是大於 5GB 檔案也能完成下載 感謝收看～ References https://github.com/tonikelope/megabasterd https://us-proxy.org/","link":"/2021/10/13/crack_mega_limit/"},{"title":"幫網站畫圖標","text":"幫網站畫圖標 最近在瀏覽網站時突然覺得netflix 的圖標讓人印象深刻，突然想到自己的網站上一直沒有圖標，於是決定來幫網站加個圖標ＸＤ netflix 圖標 試畫了幾版 第一版 第一版 網站利用英文名稱 Mike 的第一個英文字母 M 為主體(事實上是因為沒有美術天分不知道怎麼畫XD)，第一版畫完後總覺得哪裡不太對近，觀察完後發現現在許多圖標設計好像都是將背景色圖滿，而圖標用白色的字體，於是就照著Yahoo, Mozilla 的樣式進行一下修正。 第二版 第二版 因為第一版顏色有點太刺眼於是修正了顏色，並且將字體修細，但是還是覺得有點怪怪的。 第三版 第三版 參考了FlatColor 網站的顏色，挑選了一個比較好看的顏色取代~ 第四版 第四版 後來想想 M 好像有點太常見，所以就將字體 90 度旋轉變成 Sigma ，隨然沒有實質上的意義，但感覺會比較好記，而且看起來好像比較炫炮，美觀上好像也比較好一些!? 然後配合黑白的網站顏色也把圖標改成暗色系為底 XD 結論 美術設計真D好深奧 QAQ","link":"/2020/08/02/icon_design/"},{"title":"解題常用排序演算法 (附上動圖)","text":"排序演算法是許多題目的基礎概念，解題時有許多技巧也是由排序演算法所衍生，使用 python3 實作，並且附上網路的動態圖片。 簡單排序 - O( N^2 ) Bubble Sort 1234567# 兩兩相比, 將大的放到後面， 每一回合會把一個key 放到正確位置(最後方的key)def bubble_sort(nums): l = len(nums) for i in range(l): for j in range(i-1): if nums[i] &lt; nums[j]: nums[i] , nums[j] = nums[j], nums[i] GIF 圖片來源： https://wangonya.com/blog/js-sort-1/ Insertion Sort class:'lineNo'12345678# 從 idx 0 開始一路往下走，並每輪把當前 pivot 插入先前已排序的數組中的正確位置def insert_sort(nums): for i in range(len(nums)): pos, cur = i, nums[i] while pos &gt; 0 and nums[pos-1] &gt; cur: nums[pos] = nums[pos-1] # move one-step forward pos -= 1 nums[pos] = cur GIF 圖片來源 : https://dev.to/wangonya/sorting-algorithms-with-javascript-part-1-4aca Selection Sort 123456789# 每次當前回合最小的和最左邊未排序的數字(index: i)交換def selection_sort(nums): for i in range(len(nums)): pivot = i for j in range(i+1,len(nums)): if nums[j] &lt; nums[pivot]: pivot = j nums[i-1],nums[pivot] = nums[pivot] , nums[i-1] GIF 圖片來源 : https://codepumpkin.com/selection-sort-algorithms/ 高等排序 - O( NLogN ) Merge Sort 123456789101112131415# divide and conqure 技巧, 每次把串列對半切，並且串列長度&lt;=1 時,開始 mergedef merge_sort(nums): if len(nums) &lt;= 1 : return nums m = len(nums)//2 l = merge_sort(nums[:m]) r = merge_sort(nums[m:]) res = [] while l and r : if l[0] &lt; r[0]: res.append(l.pop(0)) else: res.append(r.pop(0)) res += l or r return res GIF 圖片來源 : https://codepumpkin.com/selection-sort-algorithms/ Quick Sort 123456789101112131415161718192021# Lomuto Version # 每一 run 將第最後一個元素當比較值 pivot, # 用 idx 紀錄pivot 應該放的位置# 並且依序 &lt;= pivot 的放右邊, &gt; pivot 的放左邊def quick_sort(nums): if len(nums) &lt;= 1: return nums idx = 0 pivot = nums[-1] for i in range(len(nums)-1): if nums[i] &lt;= pivot : nums[i] , nums[idx] = nums[idx] , nums[i] idx += 1 nums[idx] , nums[-1] = nums[-1] ,nums[idx] l = quick_sort(nums[:idx]) r = quick_sort(nums[idx+1:]) return l + [nums[idx]] + r GIF 圖片來源 : https://www.codesdope.com/course/algorithms-quicksort/ Merge sort 以及 Quick sort 部份為了簡潔所以把 divide, conquer 兩部份寫在一起, 而quick sort 用的是Lomuto 的版本(私心認為比較好理解XD),Hoare 的版本可以參考這裡 ,謝謝收看(ﾉ&gt;ω&lt;)ﾉ ～～","link":"/2019/11/20/sort_gif/"},{"title":"2019.12 九州旅遊","text":"2019.12 九州旅遊 前言 十月底剛結束了4 個月的軍事訓練役，距離原先12月開始工作時間還有一個月， 剛好又看到 Facebook 上面的廣告寫到日北楓葉盛開， 心血來潮下就決定跟著家人一起到日本進行旅遊， 而過去跟父母出遊往往都是跟團， 不過因為過往經驗跟團往往時間較為緊湊， 於是這次選自由行的方式進行旅遊。 行程細項 日期：2019/12/02 - 2019/12/07 天數：5天 地點：日本北九州 去程航空：華航 返程航空：華航 去程航行時間：06:50 - 09:55 返程航行時間：18:30 - 20:10 行程細項 第一天 凌晨四點左右搭車前往機場，並在機場隨便吃一下後就準備登機，接著在機上吃早餐，下飛機後先到飯店放行李，並搭著地鐵到太宰府遊玩。 搭飛機的父母 前兩天住的飯店 太宰府 太宰府 太宰府的梅枝餅 太宰府的楓葉 太宰府街道 第二天 第二天搭乘由布院之森到由布院，並走訪金鱗湖，晚上回到博多車站吃飯~ 由布院街道 由布院街道 由布院街道 由布院街道上的餐車 由布院街道 金鱗湖 由布院童話村Floral Village 童話村當中的松鼠 由布院之森 回程の我 &gt;&lt; 第三天 第三天搭乘 JR 音速到門司港，門司港吃燒咖哩，搭船到下關，並到唐戶市場買海鮮、昆布，走訪馬關條約的簽約地點春帆樓，以及赤間神宮，晚上回到博多車站的聖誕市集逛逛。 博多地鐵站 門司港拍照的爸媽 門司港必吃的燒咖哩 渡船口 唐戶市場 馬關條約春帆樓，李鴻章座位 赤間神宮 赤間神宮前面拍照的小朋友 博多車站聖誕市集 博多車站聖誕市集 第四天 搭乘 JR 海鷗到長崎，平和紀念公園，並到核爆地觀摩，晚上到博多運河城光逛逛~ JR 海鷗 平和紀念公園 象徵和平的雕像，指天的右手象徵著原子彈的威脅，水平伸展的左手象徵和平。 平和紀念公園的雕像 象徵祈福的紙鶴 平和紀念公園 爆心地公園的雕像，廣島與長崎原子彈爆炸發生在第二次世界大戰末期，美軍在1945年8月6日與8月9日，分別在日本的廣島市和長崎市投下兩枚原子彈，這是歷史上人類第一次且唯一一次在戰爭中使用核武器 ,資料來源:維基百科。 爆心地公園中為喪者的祈福紙球、紙鶴。 爆心地公園中的雕像。 博多運河城。 博多運河城。 第五天 做地鐵到天神，回國前買點東西回去～ 天神町地下街 午餐拉麵 日本必來的免稅店 bic camera 購買的鍵盤 花費 項目 單價 數量 金額 (NTD) JR_PASS 三日卷 2280 3人 6460 Klook 機場接送 672 1 趟 672 台北 福岡 來回機票 8112 3人 24336 JR_PASS 湯布院來回 座位預定票 560 3 人 1679 Miyako Hotel Hakata (五星 ,三人房 , 附早餐) 6541 2 晚 13,083 Hotel Wing (三星,兩人房 , 無早餐) 3011*2 2 晚 12,047 SUGOCA 悠遊卡 614 2 張 1,268 總價 59924.9","link":"/2019/12/11/2019_12_Kyushu/"},{"title":"Vespa ai 筆記 (一)","text":"Vespa ai 筆記 (一) Vespa 是什麼 一般講到vespa 通常第一個聯想到的往往是某個機車品牌XD，然而除了機車品牌外它同時也是一個開源的搜索引擎，Vespa 由 Yahoo! ( verizon media ) 於 2017年9月發布， Vespa 用於對海量數據集進行低延遲計算的引擎，它負責存儲和索引數據資料。同時 Vespa 中也提供了: Indexing, Searching, Ranking, Grouping，等等許多自定義的擴展功能。 來看看官方的描述： 第一次看到是不是會有種不明覺厲的感覺XD 而也因為這些特性我們常常利用vespa 來建立: 搜尋引擎 個人化推薦系統 需要 Realtime 數據顯示的地圖，標籤，圖形…等等 而 Vespa 團隊因為近期因為 CORD-19 (新型冠壯肺炎)的快速傳染，利用Allen Institute for AI 所釋出的公開資料集，建立了新型冠壯病毒的搜尋網站，而該專案也是完全開源的(點這裡查看)。 Vespa 的索引概念以及運作原理 Vespa 的主要架構圖如下 主要可以分為三塊 Stateless Container Cluster Content Cluster Admin and config clusters Stateless Container Cluster 為架構圖中藍色的部份，主要負責 Document 的 get, put, update, remove 等操作，當有外部的 request 打進來時，Container cluster 會自動將操作送到對應的 content node 中進行。自定義的排序方法、文件處理、其他功能也在此 cluster 中進行 。 Content Cluster 相較於前者，Content Cluster 負責的業務則相對簡單，負責資料的儲存，會將同一份資料複製到多個節點上，以及執行從 Container Cluster 所要求的操作，當所有 Cluster 中對應的節點執行完操作後，content Cluster 會自動匯總結果。 而該 cluster 會自動平衡節點中的數據量，並且維持 Redundancy 已提高容錯性，針對壞掉的節點自動進行故障轉移，保證高可用行並自動恢復。 Admin and config clusters 除了上述兩種外還有第三種主要負責一些節點設定等等。 利用 Vespa 動手實做一個簡單的搜尋引擎吧！！ 介紹 利用 WorldPress 的資料集建立一個部落格文章推薦系統，實做用戶文章搜尋，以及個人文章推薦的功能，而該文章由Vespa Team 所發布可以點這裡查看原文。 Prerequisites Docker Git OS : macOS or Linux(Ubuntu, CentOS …) Architecture: x86_64 Minimum 6GB memory dedicated to Docker (the default is 2GB on Macs) - 10G for monitoring section. Dataset kaggle dataset Post 的基本屬性 Column Description post_id unique numerical id identifying the blog post date_gmt string representing date of blog post creation in GMT format yyyy-mm-dd hh:mm:ss author unique numerical id identifying the author of the blog post url blog post URL title blog post title blog unique numerical id identifying the blog that the blog post belongs to tags array of strings representing the tags of the blog posts content body text of the blog post, in html format categories array of strings representing the categories the blog post was assigned to Requirements 在開始前必須要先建立環境，利用官方所提供的 docker image 可以快速的把環境建好～ 建立 &amp; 切換 工作目錄 12$ mkdir blog$ cd blog 建立 Docker 環境 123$ docker run -m 10G --detach --name vespa --hostname vespa-tutorial \\ --privileged --volume `pwd`:/app \\ --publish 8080:8080 --publish 19092:19092 vespaengine/vespa 若上述步驟遇到 docker memory limit 解法參考 link 確認 server 建立成功，會得到 200 OK 的 response 1$ docker exec vespa bash -c 'curl -s --head http://localhost:19071/ApplicationStatus' Clone Git Repo ，會利用當中的 script 產生 data 1$ git clone --depth 1 https://github.com/vespa-engine/sample-apps.git 下載Feeding 時所需的資料點這裡 至此恭喜您已經完成所有的環境建立步驟~ 加入設定檔 加入必要的設定檔 在剛剛空的資料夾中建立對應資料夾 application 1$ mkdir application 在 application 目錄中建立 services.xml，用來定義需要多少 server 的基本配置。 123456789101112131415161718192021222324252627282930&lt;?xml version='1.0' encoding='UTF-8'?&gt;&lt;services version=&quot;1.0&quot;&gt; &lt;container id=&quot;default&quot; version=&quot;1.0&quot;&gt; &lt;search&gt;&lt;/search&gt; &lt;document-api&gt;&lt;/document-api&gt; &lt;nodes&gt; &lt;node hostalias=&quot;node1&quot;&gt;&lt;/node&gt; &lt;/nodes&gt; &lt;/container&gt; &lt;content id=&quot;blog_post&quot; version=&quot;1.0&quot;&gt; &lt;redundancy&gt;1&lt;/redundancy&gt; &lt;search&gt; &lt;visibility-delay&gt;1.0&lt;/visibility-delay&gt; &lt;/search&gt; &lt;documents&gt; &lt;document mode=&quot;index&quot; type=&quot;blog_post&quot;&gt;&lt;/document&gt; &lt;/documents&gt; &lt;nodes&gt; &lt;node hostalias=&quot;node1&quot; distribution-key=&quot;0&quot;&gt;&lt;/node&gt; &lt;/nodes&gt; &lt;engine&gt; &lt;proton&gt; &lt;searchable-copies&gt;1&lt;/searchable-copies&gt; &lt;/proton&gt; &lt;/engine&gt; &lt;/content&gt;&lt;/services&gt; 用以定義上述架構圖中的 container cluster 設定 query endpoint ， 預設為 8080 port 設定 Feeding 文件的 endpoint 設定該 cluster 中需要多少節點 設定 content cluster 設定需要多少份複製文件以供節點錯誤時進行自動回復 指定 node 中的 document schema (sd 檔) 設定 cluster 中的 node 在 application 目錄中建立 hosts.xml，由於我們使用docker 在 local host 建立，只需要定義為如下即可。 123456&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot; ?&gt;&lt;hosts&gt; &lt;host name=&quot;localhost&quot;&gt; &lt;alias&gt;node1&lt;/alias&gt; &lt;/host&gt;&lt;/hosts&gt; 建立 application 目錄中建立 blog 要被搜尋的文件的 blog_post.sd ， 路徑 application/schemas/blog_post.sd 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748schema blog_post { document blog_post { field date_gmt type string { indexing: summary } field language type string { indexing: summary } field author type string { indexing: summary } field url type string { indexing: summary } field title type string { indexing: summary | index } field blog type string { indexing: summary } field post_id type string { indexing: summary } field tags type array&lt;string&gt; { indexing: summary } field blogname type string { indexing: summary } field content type string { indexing: summary | index } field categories type array&lt;string&gt; { indexing: summary } field date type int { indexing: summary | attribute } } fieldset default { fields: title, content } rank-profile post inherits default { first-phase { expression:nativeRank(title, content) } }} 當中 indexing 設定了vespa 會如何 indexing 該欄位 index : 對該欄位界建立 index 供搜尋時使用 attribute : 會將該欄位存在 memory 中，供排序、搜尋、合併時使用 summary : 定義使否出現在 summary 中，搜尋的結果是否會將該欄位顯示 建立完成後application 目錄下應該會長這樣 部屬應用到本機端 12$ docker exec vespa bash -c '/opt/vespa/bin/vespa-deploy prepare /app/application &amp;&amp; \\ /opt/vespa/bin/vespa-deploy activate' 接著去打 http://localhost:8080/ApplicationStatus 就能看到一些基本資訊，說明應用已經成功部屬。 Feeding Data 接著我們將必要的資料 Feeding 到搜尋引擎中。 將剛剛下載的文檔解壓縮 擷取前10000 筆資料(也可以跳過這步驟使用整個dataset XD) ，並利用script 轉成 對應的 JSON 格式，以降低處理時間。 12$ head -10000 trainPosts.json &gt; trainPostsSmall.json$ python sample-apps/blog-tutorial-shared/src/python/parse.py trainPostsSmall.json &gt; tutorial_feed.json 利用 Vespa Team 提供的 JAVA Feeding API 將資料打進 Vespa 搜尋引擎中 12$ docker exec vespa bash -c 'java -jar /opt/vespa/lib/jars/vespa-http-client-jar-with-dependencies.jar \\ --verbose --file /app/tutorial_feed.json --host localhost --port 8080' 利用 Metrics API 確認 feeding 結果，若 Feeding 成功則會看見對應的 feeding 筆數。 1$ curl -s &quot;http://localhost:19092/metrics/v1/values&quot; | tr &quot;,&quot; &quot;\\n&quot; | grep content.proton.documentdb.documents.active 現在我們可以用對應的 Doc ID 去要資料。 1$ curl -s 'http://localhost:8080/document/v1/blog-search/blog_post/docid/507823' | json_pp Query 用自訂的 query 去搜尋引擎拉東西 通常 vespa 利用 HTTP GET, HTTP POST 的 request 會長得像下面格式。 1&lt;host:port&gt;/&lt;search&gt;?&lt;yql=value1&gt;&amp;&lt;param2=value2&gt;... 我們可以用以下兩種形式的Query 去要資料，而使用的為YQL 的Query 語法 。 12curl -s -H &quot;Content-Type: application/json&quot; --data '{&quot;yql&quot; : &quot;select * from sources * where default contains \\&quot;music\\&quot;;&quot;}' \\http://localhost:8080/search/ | python -m json.tool 1$ curl -s 'http://localhost:8080/search/?yql=select+*+from+sources+*+where+default+contains+%22music%22%3B' | python -m json.tool 以上兩種都是利用搜尋 trump 出現在 default 欄位中的 item， 而這邊的 defaut 指的是我們在 sd 中所建立的 field set : default，當中包含了 title, content 兩個欄位，因此會對這兩個欄位進行 filter。 自定義排序功能 Relevance and Ranking，我們可以藉由自定義排功能，根據不同欄位計算相對應的權重，計算文章的相關性，用以實現自己想要的排序結果。 首先我們在先前定義好的SD 檔中新增 popularity 欄位，以及新的排序公式 123field popularity type double { indexing: summary | attribute} 12345rank-profile post_popularity inherits default { first-phase { expression: nativeRank(title, content) + 10 * if(isNan(attribute(popularity)), 0, attribute(popularity)) }} 我們新增了一條公式，繼承原本的rank-profile，並且覆寫掉第一階段的排序，將原本計算的分數加上 10 * popularity 欄位的值作為新的排序依據。 將新的應用部屬 12$ docker exec vespa bash -c '/opt/vespa/bin/vespa-deploy prepare /app/application &amp;&amp; \\ /opt/vespa/bin/vespa-deploy activate' Feeding 含有popularity 的文件 12345$ python sample-apps/blog-tutorial-shared/src/python/parse.py \\ -p sample-apps/blog-tutorial-shared/sample_posts.json &gt; tutorial_feed_with_popularity.json$ docker exec vespa bash -c 'java -jar /opt/vespa/lib/jars/vespa-http-client-jar-with-dependencies.jar \\ --verbose --file /app/tutorial_feed_with_popularity.json --host localhost --port 8080' 完成後我們再進行 curl ，比較新舊query profile 的差異 原本的返回結果 1curl -s -H &quot;Content-Type: application/json&quot; --data '{&quot;yql&quot; : &quot;select title, content, popularity from sources * where default contains \\&quot;music\\&quot;;&quot;}' http://localhost:8080/search/ | json_pp 使用新的popularity rank profile 的結果 12curl -s -H &quot;Content-Type: application/json&quot; --data '{&quot;yql&quot; : &quot;select * from sources * where default contains \\&quot;music\\&quot;;&quot;, &quot;ranking&quot; : &quot;post_popularity&quot;}' \\http://localhost:8080/search/ | json_pp 我們可以發現套用了post_popularity 的 rank-profile 排序變成給予popularity 的 item 較高排序權重，即便 content 跟 title 中都沒有出現相對應的搜尋文字。 左:default rank profile 右:使用popularity rank profile 至此我們已經完成了 環境搭建 Vespa 引擎設定 部屬應用 Feeding 資料 利用 YQL 進行簡單的搜尋 自訂義排序 下篇文章會繼續實做個人化的推薦系統~ 結論 沒意外的話應該會將剩餘的內容切分到下幾篇文章 XD，本身對 Vespa 的用法也只是摸到皮毛，當中內部許多功能的實現方法也還沒有深入的研究，一樣還在持續的學習中，若文章中有錯誤的地方希望能鞭小力點XD，現今開源引擎較廣為人知的是 Elasticsearch, SOLR ， 然而 Vespa 的出現也提供了開發者一個新的選擇 ~ References https://vespa.ai/ https://cord19.vespa.ai/ https://towardsdatascience.com/vespa-ai-and-the-cord-19-public-api-a714b942172f","link":"/2020/08/02/vepsa_note_1/"}],"tags":[{"name":"Shopping","slug":"Shopping","link":"/tags/Shopping/"},{"name":"EC","slug":"EC","link":"/tags/EC/"},{"name":"e-commerce","slug":"e-commerce","link":"/tags/e-commerce/"},{"name":"Taobao","slug":"Taobao","link":"/tags/Taobao/"},{"name":"Blog","slug":"Blog","link":"/tags/Blog/"},{"name":"Django","slug":"Django","link":"/tags/Django/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"GCP","slug":"GCP","link":"/tags/GCP/"},{"name":"GAE","slug":"GAE","link":"/tags/GAE/"},{"name":"Google Cloud Platform","slug":"Google-Cloud-Platform","link":"/tags/Google-Cloud-Platform/"},{"name":"Google App Engine","slug":"Google-App-Engine","link":"/tags/Google-App-Engine/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"Mega","slug":"Mega","link":"/tags/Mega/"},{"name":"Limit","slug":"Limit","link":"/tags/Limit/"},{"name":"Downloader","slug":"Downloader","link":"/tags/Downloader/"},{"name":"Tool","slug":"Tool","link":"/tags/Tool/"},{"name":"Api","slug":"Api","link":"/tags/Api/"},{"name":"Hack","slug":"Hack","link":"/tags/Hack/"},{"name":"Icon","slug":"Icon","link":"/tags/Icon/"},{"name":"Design","slug":"Design","link":"/tags/Design/"},{"name":"Leetcode","slug":"Leetcode","link":"/tags/Leetcode/"},{"name":"Sort","slug":"Sort","link":"/tags/Sort/"},{"name":"Algorithm","slug":"Algorithm","link":"/tags/Algorithm/"},{"name":"Japan","slug":"Japan","link":"/tags/Japan/"},{"name":"Kyushu","slug":"Kyushu","link":"/tags/Kyushu/"},{"name":"Vespa","slug":"Vespa","link":"/tags/Vespa/"},{"name":"Yahoo","slug":"Yahoo","link":"/tags/Yahoo/"},{"name":"Opensource","slug":"Opensource","link":"/tags/Opensource/"},{"name":"Search engine","slug":"Search-engine","link":"/tags/Search-engine/"},{"name":"Real time","slug":"Real-time","link":"/tags/Real-time/"}],"categories":[]}